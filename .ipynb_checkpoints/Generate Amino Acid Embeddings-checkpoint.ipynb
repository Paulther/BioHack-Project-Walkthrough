{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ace1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "from Bio import SeqIO\n",
    "import Bio.PDB\n",
    "import pickle as pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GENConv\n",
    "from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.aggr import MeanAggregation\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from Bio import PDB\n",
    "from rdkit import Chem\n",
    "import blosum as bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5eaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    pdbfiles: str = \"/home/paul/Desktop/BioHack-Project-Walkthrough/pdbind-refined-set/\"\n",
    "    AA_mol2_files: str = \"/home/paul/Desktop/BioHack-Project-Walkthrough/AA_mol2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bb3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('atom2emb.pkl', 'rb') as f:\n",
    "    atom2emb = pickle.load(f)\n",
    "    \n",
    "with open('bond_type_dict.pkl', 'rb') as f:\n",
    "    bond_type_dict = pickle.load(f)\n",
    "    \n",
    "one_letter_to_three_letter_dict = {'G':'gly',\n",
    "                                   'A':'ala',\n",
    "                                   'V':'val',\n",
    "                                   'C':'cys',\n",
    "                                   'P':'pro',\n",
    "                                   'L':'leu',\n",
    "                                   'I':'ile',\n",
    "                                   'M':'met',\n",
    "                                   'W':'trp',\n",
    "                                   'F':'phe',\n",
    "                                   'K':'lys',\n",
    "                                   'R':'arg',\n",
    "                                   'H':'his',\n",
    "                                   'S':'ser',\n",
    "                                   'T':'thr',\n",
    "                                   'Y':'tyr',\n",
    "                                   'N':'asn',\n",
    "                                   'Q':'gln',\n",
    "                                   'D':'asp',\n",
    "                                   'E':'glu'\n",
    "    \n",
    "}\n",
    "\n",
    "def BLOSUM_encode_single(seq,AA_dict):\n",
    "    allowed = set(\"gavcplimwfkrhstynqdeuogavcplimwfkrhstynqde\")\n",
    "    if not set(seq).issubset(allowed):\n",
    "        invalid = set(seq) - allowed\n",
    "        raise ValueError(f\"Sequence has broken AA: {invalid}\")\n",
    "    vec = AA_dict[seq]\n",
    "    return vec\n",
    "\n",
    "matrix = bl.BLOSUM(62)\n",
    "allowed_AA = \"GAVCPLIMWFKRHSTYNQDE\"\n",
    "BLOSUM_dict_three_letter = {}\n",
    "for i in allowed_AA:\n",
    "    vec = []\n",
    "    for j in allowed_AA:\n",
    "        vec.append(matrix[i][j])\n",
    "    BLOSUM_dict_three_letter.update({one_letter_to_three_letter_dict[i]:torch.Tensor(vec)})\n",
    "    \n",
    "def read_mol2_bonds_and_atoms(mol2_file):\n",
    "    bonds = []\n",
    "    bond_types = []\n",
    "    atom_types = {}\n",
    "    atom_coordinates = {}\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_bonds = False\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>BOND':\n",
    "                reading_bonds = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip().startswith('@<TRIPOS>SUBSTRUCTURE'):\n",
    "                break\n",
    "            elif reading_bonds and line.strip().startswith('@<TRIPOS>'):\n",
    "                reading_bonds = False\n",
    "            elif reading_atoms and line.strip().startswith('@<TRIPOS>'):\n",
    "                reading_atoms = False\n",
    "\n",
    "\n",
    "            if reading_bonds:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    atom1_index = int(parts[1])\n",
    "                    atom2_index = int(parts[2])\n",
    "                    bond_type = parts[3]\n",
    "                    bonds.append((atom1_index, atom2_index))\n",
    "                    bond_types.append(bond_type)\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 6:\n",
    "                    atom_index = int(parts[0])\n",
    "                    atom_type = parts[5]\n",
    "                    x, y, z = float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                    atom_types[atom_index] = atom_type.split('.')[0]\n",
    "                    atom_coordinates[atom_index] = (x, y, z)\n",
    "\n",
    "    return bonds, bond_types, atom_types, atom_coordinates  \n",
    "\n",
    "def molecule2graph_AA(filename,map_distance, norm_map_distance = 12.0):\n",
    "    node_feature = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    mol2_file = CFG.AA_mol2_files+filename\n",
    "    bonds, bond_types, atom_types, atom_coordinates = read_mol2_bonds_and_atoms(mol2_file)\n",
    "    for atom in atom_types:\n",
    "        node_feature.append(torch.Tensor(atom2emb[atom_types[atom]]))\n",
    "    \n",
    "\n",
    "    for atom1 in range(1, len(atom_types)+1):\n",
    "        for atom2 in range(atom1 + 1, len(atom_types)+1):\n",
    "            bonded_flag = 0\n",
    "            for i, bond in enumerate(bonds):\n",
    "                if (atom1 in bond) and (atom2 in bond):\n",
    "                    edge_index.append([bond[0] - 1,bond[1] - 1])\n",
    "                    coord1 = np.array(atom_coordinates[bond[0]])\n",
    "                    coord2 = np.array(atom_coordinates[bond[1]])\n",
    "                    dist = math.dist(coord1, coord2)\n",
    "                    d = []\n",
    "                    for l in range(12):\n",
    "                        d.append(np.exp((-1.0*(dist - 2.0*(l + 0.5))**2.0)/norm_map_distance))\n",
    "                    bond_type = bond_type_dict[bond_types[i]]\n",
    "                    edge_attr.append(np.hstack((d,d,d,d,d,d,d,d,d,bond_type)))\n",
    "                    bonded_flag = 1\n",
    "                \n",
    "            if bonded_flag == 0:\n",
    "                coord1 = np.array(atom_coordinates[atom1])\n",
    "                coord2 = np.array(atom_coordinates[atom2])\n",
    "                dist = math.dist(coord1, coord2)\n",
    "                if dist < map_distance:\n",
    "                    edge_index.append([atom1 - 1,atom2 - 1])\n",
    "                    d = []\n",
    "                    for l in range(12):\n",
    "                        d.append(np.exp((-1.0*(dist - 2.0*(l + 0.5))**2.0)/norm_map_distance))\n",
    "                    bond_type = bond_type_dict['nc']\n",
    "                    edge_attr.append(np.hstack((d,d,d,d,d,d,d,d,d,bond_type)))\n",
    "\n",
    "    \n",
    "    edge_index = np.array(edge_index)\n",
    "    edge_index = edge_index.transpose()\n",
    "    edge_index = torch.Tensor(edge_index)\n",
    "    edge_index = edge_index.to(torch.int64)\n",
    "    edge_attr = torch.Tensor(np.array(edge_attr))\n",
    "    node_feature = torch.stack(node_feature)\n",
    "    \n",
    "    #Master_node\n",
    "    new_edge_index = []\n",
    "    new_edge_attr = []\n",
    "    node_features = torch.cat((node_feature,torch.zeros(len(atom2emb['N'])).unsqueeze(0)),dim = 0)\n",
    "    \n",
    "    for i in range(len(node_features) - 1):\n",
    "        new_edge_index.append([i,int(len(node_features)-1)])\n",
    "        bond_type = bond_type_dict['nc']\n",
    "        new_edge_attr.append(np.hstack((np.zeros(9*len(d)),bond_type)))\n",
    "    \n",
    "    new_edge_index = np.array(new_edge_index)\n",
    "    new_edge_index = new_edge_index.transpose()\n",
    "    new_edge_index = torch.Tensor(new_edge_index)\n",
    "    new_edge_index = new_edge_index.to(torch.int64)\n",
    "    new_edge_attr = torch.Tensor(np.array(new_edge_attr))    \n",
    "    \n",
    "    edge_index = torch.cat((edge_index,new_edge_index), dim = 1)\n",
    "    edge_attr = torch.cat((edge_attr,new_edge_attr), dim = 0)\n",
    "    \n",
    "    graph = Data(x = node_feature, edge_index = edge_index,edge_attr = edge_attr)#, pos = new_mol_coords)\n",
    "    graph.label = filename.split('.')[0]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f621eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_graphs = []\n",
    "for filename in os.listdir(CFG.AA_mol2_files):\n",
    "    AA_graphs.append(molecule2graph_AA(filename,12.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1f4afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[21, 133], edge_index=[2, 231], edge_attr=[231, 114], label='tyr')\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(AA_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99fbc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim = 0)\n",
    "for i, graph in enumerate(AA_graphs):\n",
    "    AA_graphs[i].y = softmax(BLOSUM_encode_single(graph.label,BLOSUM_dict_three_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b41e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.node_feature_size = 133\n",
    "        self.node_feature_hidden_size = 133\n",
    "        self.node_feature_size_out = 20\n",
    "        self.conv1 = GENConv(self.node_feature_size,self.node_feature_hidden_size,aggr = 'mean',edge_dim = 114, num_layer = 2,norm = 'layer')\n",
    "        self.conv2 = GENConv(self.node_feature_hidden_size,self.node_feature_hidden_size,aggr = 'mean',edge_dim = 114,num_layer = 2,norm = 'layer')\n",
    "        self.conv3 = GENConv(self.node_feature_hidden_size,self.node_feature_hidden_size,aggr = 'mean',edge_dim = 114,num_layer = 2,norm = 'layer')\n",
    "        self.linear1 = nn.Linear(self.node_feature_hidden_size,self.node_feature_size_out)\n",
    "        self.ReLu = nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,graph):\n",
    "        x, edge_index, edge_attr = graph.x, graph.edge_index, graph.edge_attr\n",
    "        x1 = self.conv1(x, edge_index, edge_attr)\n",
    "        x1 = self.ReLu(x1)\n",
    "        x1 = self.conv2(x1, edge_index, edge_attr)\n",
    "        x1 = self.ReLu(x1)\n",
    "        x1 = self.conv3(x1, edge_index, edge_attr)\n",
    "        x1 = x1[-1]\n",
    "        x1 = torch.tanh(x1)\n",
    "        x1 = self.linear1(x1)\n",
    "        return x1\n",
    "    \n",
    "    def encode(self,graph):\n",
    "        x, edge_index, edge_attr = graph.x,graph.edge_index,graph.edge_attr\n",
    "        x1 = self.conv1(x, edge_index,edge_attr)\n",
    "        x1 = self.ReLu(x1)\n",
    "        x1 = self.conv2(x1, edge_index,edge_attr)\n",
    "        x1 = self.ReLu(x1)\n",
    "        x1 = self.conv3(x1, edge_index,edge_attr)\n",
    "        x1 = x1[-1]\n",
    "        x1 = torch.tanh(x1)\n",
    "        return x1\n",
    "    \n",
    "    def decode(self,encoding):\n",
    "        x1 = self.linear1(encoding)\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ae0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_dl = DataLoader(AA_graphs,batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6989511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20, 133], edge_index=[2, 210], edge_attr=[210, 114], label='phe', y=[20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [62,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [63,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [64,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [65,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [66,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [67,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [68,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [69,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [70,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [71,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [72,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [73,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [74,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [75,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [76,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [77,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [78,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [79,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [80,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [0,0,0], thread: [81,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:109\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:34\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:155\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:84\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     82\u001b[0m     out \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(size)\u001b[38;5;241m.\u001b[39mscatter_add_(dim, index, src)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, inputs\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,graph):\n\u001b[1;32m     15\u001b[0m     x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mx, graph\u001b[38;5;241m.\u001b[39medge_index, graph\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[0;32m---> 16\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#,edge_attr)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mReLu(x1)\n\u001b[1;32m     18\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x1, edge_index)\u001b[38;5;66;03m#,edge_attr)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/conv/gen_conv.py:229\u001b[0m, in \u001b[0;36mGENConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m edge_attr\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlin_aggr_out\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    232\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_aggr_out(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:484\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m         aggr_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    487\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:608\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    596\u001b[0m               ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m               dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:112\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered invalid \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m                              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Net()\n",
    "model.to(DEVICE) # put on GPU\n",
    "\n",
    "# Define a loss function (e.g., Mean Squared Error) and an optimizer (e.g., Adam)\n",
    "criterion = loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000,8000], gamma=0.1)\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr = 5e-6)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000  # Adjust the number of epochs as needed\n",
    "losses = []\n",
    "lowest = 0.01\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "        \n",
    "    for batch in train_dl:\n",
    "        model.train()\n",
    "        inputs = batch[0].to(DEVICE)\n",
    "        print(inputs)\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, inputs.y)\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        inputs= inputs.to('cpu')\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "            \n",
    "    for batch in train_dl:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            inputs = batch[0].to(DEVICE)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, inputs.y)\n",
    "        \n",
    "            inputs= inputs.to('cpu')\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    val_avg_loss = val_loss / len(train_dl)\n",
    "    \n",
    "    if lowest > val_avg_loss:\n",
    "        torch.save(model.state_dict(), 'AA_encoder_11172023.pt')\n",
    "        lowest = val_avg_loss\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f} Val Loss: {val_avg_loss:.4f}')\n",
    "    \n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba217bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('AA_encoder_11172023.pt'))\n",
    "graph = random.choice(data)\n",
    "pred = model.forward(graph.to(DEVICE))\n",
    "print(pred)\n",
    "print(graph.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(graph.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4521b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('atom2emb.pkl', 'rb') as f:\n",
    "    atom2emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom2emb['Fe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_embeddings = {}\n",
    "for graph in graph_list:\n",
    "    pred = model.encode(graph[1].to(DEVICE))\n",
    "    AA_embeddings.update({upper2lower[graph[0]]:pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072be816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in AA_embeddings:\n",
    "    print(i)\n",
    "    print(AA_embeddings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe81375",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AA_embeddings_11172023.pkl', 'wb') as f:\n",
    "    pickle.dump(AA_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e2bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_symbol(atomic_number):\n",
    "    return Chem.PeriodicTable.GetElementSymbol(Chem.GetPeriodicTable(), atomic_number)\n",
    "\n",
    "def remove_hetatm(input_pdb_file, output_pdb_file):\n",
    "    # Open the input PDB file for reading and the output PDB file for writing\n",
    "    with open(input_pdb_file, 'r') as infile, open(output_pdb_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Check if the line starts with 'HETATM' (non-protein atoms)\n",
    "            if line.startswith('HETATM'):\n",
    "                continue  # Skip this line (HETATM record)\n",
    "            # Write all other lines to the output file\n",
    "            outfile.write(line)\n",
    "            \n",
    "def get_atom_types_from_sdf(sdf_file):\n",
    "    supplier = Chem.SDMolSupplier(sdf_file)\n",
    "    atom_types = set()\n",
    "\n",
    "    for mol in supplier:\n",
    "        if mol is not None:\n",
    "            atoms = mol.GetAtoms()\n",
    "            atom_types.update([atom.GetSymbol() for atom in atoms])\n",
    "\n",
    "    return sorted(list(atom_types))\n",
    "\n",
    "def get_atom_types_from_mol2_split(mol2_file):\n",
    "    atom_types = set()\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>BOND':\n",
    "                break\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    atom_type = parts[5]\n",
    "                    atom_types.add(atom_type)\n",
    "    \n",
    "    atom_types_split = set()\n",
    "    for atom in atom_types:\n",
    "        atom_types_split.add(str(atom).split('.')[0])\n",
    "        \n",
    "\n",
    "    return sorted(list(atom_types_split))\n",
    "\n",
    "def get_atom_types_from_mol2(mol2_file):\n",
    "    atom_types = set()\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>BOND':\n",
    "                break\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    atom_type = parts[5]\n",
    "                    atom_types.add(atom_type)\n",
    "\n",
    "    return sorted(list(atom_types))\n",
    "\n",
    "def get_atom_list_from_mol2_split(mol2_file):\n",
    "    atoms = []\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>BOND':\n",
    "                break\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    atom_type = parts[5]\n",
    "                    atoms.append(atom_type)\n",
    "    \n",
    "    atom_list = []\n",
    "    for atom in atoms:\n",
    "        atom_list.append(str(atom).split('.')[0])\n",
    "        \n",
    "\n",
    "    return atom_list\n",
    "\n",
    "def get_atom_list_from_mol2(mol2_file):\n",
    "    atoms = []\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>BOND':\n",
    "                break\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    atom_type = parts[5]\n",
    "                    atoms.append(atom_type)\n",
    "\n",
    "    return atoms\n",
    "\n",
    "def get_bond_types_from_mol2(mol2_file):\n",
    "    bond_types = set()\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_bonds = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>BOND':\n",
    "                reading_bonds = True\n",
    "                continue\n",
    "            elif reading_bonds and line.strip().startswith('@<TRIPOS>'):\n",
    "                break\n",
    "\n",
    "            if reading_bonds:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    bond_type = parts[3]\n",
    "                    bond_types.add(bond_type)\n",
    "\n",
    "    return sorted(list(bond_types))\n",
    "\n",
    "def read_mol2_bonds(mol2_file):\n",
    "    bonds = []\n",
    "    bond_types = []\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_bonds = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>BOND':\n",
    "                reading_bonds = True\n",
    "                continue\n",
    "            elif reading_bonds and line.strip().startswith('@<TRIPOS>'):\n",
    "                break\n",
    "\n",
    "            if reading_bonds:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    atom1_index = int(parts[1])\n",
    "                    atom2_index = int(parts[2])\n",
    "                    bond_type = parts[3]\n",
    "                    bonds.append((atom1_index, atom2_index))\n",
    "                    bond_types.append(bond_type)\n",
    "\n",
    "    return bonds, bond_types\n",
    "\n",
    "def calc_residue_dist(residue_one, residue_two) :\n",
    "    \"\"\"Returns the C-alpha distance between two residues\"\"\"\n",
    "    diff_vector  = residue_one[\"CA\"].coord - residue_two[\"CA\"].coord\n",
    "    return np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "\n",
    "def calc_dist_matrix(chain_one, chain_two) :\n",
    "    \"\"\"Returns a matrix of C-alpha distances between two chains\"\"\"\n",
    "    answer = np.zeros((len(chain_one), len(chain_two)), float)\n",
    "    for row, residue_one in enumerate(chain_one) :\n",
    "        for col, residue_two in enumerate(chain_two) :\n",
    "            answer[row, col] = calc_residue_dist(residue_one, residue_two)\n",
    "    return answer\n",
    "\n",
    "def calc_contact_map(uniID,map_distance):\n",
    "    pdb_code = uniID\n",
    "    pdb_filename = uniID+\"_pocket_clean.pdb\"\n",
    "    structure = Bio.PDB.PDBParser(QUIET = True).get_structure(pdb_code, (CFG.pdbfiles +'/'+pdb_code+'/'+pdb_filename))\n",
    "    model = structure[0]\n",
    "    flag1 = 0\n",
    "    flag2 = 0\n",
    "    idx = 0\n",
    "    index = []\n",
    "    chain_info = []\n",
    "    \n",
    "    for chain1 in model:\n",
    "        for resi in chain1:\n",
    "            index.append(idx)\n",
    "            idx += 1\n",
    "            chain_info.append([chain1.id,resi.id])\n",
    "        for chain2 in model:\n",
    "            if flag1 == 0:\n",
    "                dist_matrix = calc_dist_matrix(model[chain1.id], model[chain2.id])\n",
    "            else:\n",
    "                new_matrix = calc_dist_matrix(model[chain1.id], model[chain2.id])\n",
    "                dist_matrix = np.hstack((dist_matrix,new_matrix))\n",
    "            flag1 += 1\n",
    "        flag1 = 0\n",
    "        if flag2 == 0:\n",
    "            top_matrix = dist_matrix\n",
    "        else:\n",
    "            top_matrix = np.vstack((top_matrix,dist_matrix))\n",
    "        flag2 += 1\n",
    "    \n",
    "    contact_map = top_matrix < map_distance\n",
    "    return contact_map, index, chain_info\n",
    "\n",
    "one_letter_to_three_letter_dict = {'G':'gly',\n",
    "                                   'A':'ala',\n",
    "                                   'V':'val',\n",
    "                                   'C':'cys',\n",
    "                                   'P':'pro',\n",
    "                                   'L':'leu',\n",
    "                                   'I':'ile',\n",
    "                                   'M':'met',\n",
    "                                   'W':'trp',\n",
    "                                   'F':'phe',\n",
    "                                   'K':'lys',\n",
    "                                   'R':'arg',\n",
    "                                   'H':'his',\n",
    "                                   'S':'ser',\n",
    "                                   'T':'thr',\n",
    "                                   'Y':'tyr',\n",
    "                                   'N':'asn',\n",
    "                                   'Q':'gln',\n",
    "                                   'D':'asp',\n",
    "                                   'E':'glu'\n",
    "    \n",
    "}\n",
    "\n",
    "def BLOSUM_encode_single(seq,AA_dict):\n",
    "    allowed = set(\"gavcplimwfkrhstynqdeuogavcplimwfkrhstynqde\")\n",
    "    if not set(seq).issubset(allowed):\n",
    "        invalid = set(seq) - allowed\n",
    "        raise ValueError(f\"Sequence has broken AA: {invalid}\")\n",
    "    vec = AA_dict[seq]\n",
    "    return vec\n",
    "\n",
    "matrix = bl.BLOSUM(62)\n",
    "allowed_AA = \"GAVCPLIMWFKRHSTYNQDE\"\n",
    "BLOSUM_dict_three_letter = {}\n",
    "for i in allowed_AA:\n",
    "    vec = []\n",
    "    for j in allowed_AA:\n",
    "        vec.append(matrix[i][j])\n",
    "    BLOSUM_dict_three_letter.update({one_letter_to_three_letter_dict[i]:torch.Tensor(vec)})\n",
    "\n",
    "def uniID2graph(uniID,map_distance):\n",
    "    atom_name = 'CA'\n",
    "    node_feature = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    coord = []\n",
    "    contact_map, index, chain_info = calc_contact_map(uniID,map_distance)\n",
    "    pdb_code = uniID\n",
    "    pdb_filename = uniID+\"_pocket_clean.pdb\"\n",
    "    structure = Bio.PDB.PDBParser(QUIET = True).get_structure(pdb_code, (CFG.pdbfiles +'/'+pdb_code+'/'+pdb_filename))\n",
    "    model = structure[0]\n",
    "    \n",
    "    for i in index:\n",
    "        node_feature.append(one_hot_encode_single_res(model[chain_info[i][0]][chain_info[i][1]].get_resname()))\n",
    "        coord.append(model[chain_info[i][0]][chain_info[i][1]]['CA'].coord)\n",
    "        for j in index:\n",
    "            if contact_map[i,j] == 1:\n",
    "                edge_index.append([i,j])\n",
    "                diff_vector = model[chain_info[i][0]][chain_info[i][1]]['CA'].coord - model[chain_info[j][0]][chain_info[j][1]]['CA'].coord\n",
    "                dist = (np.sqrt(np.sum(diff_vector * diff_vector))/map_distance)\n",
    "                bond_type = bond_type_dict['nc']\n",
    "                edge_attr.append(np.hstack((dist,bond_type)))\n",
    "                            \n",
    "    edge_index = np.array(edge_index)\n",
    "    edge_index = edge_index.transpose()\n",
    "    edge_index = torch.Tensor(edge_index)\n",
    "    edge_index = edge_index.to(torch.int64)\n",
    "    edge_attr = torch.Tensor(edge_attr)\n",
    "    node_feature = torch.stack(node_feature)\n",
    "    graph = Data(x = node_feature, edge_index = edge_index,edge_attr = edge_attr)\n",
    "    return graph, coord\n",
    "\n",
    "def read_mol2_bonds_and_atoms(mol2_file):\n",
    "    bonds = []\n",
    "    bond_types = []\n",
    "    atom_types = {}\n",
    "    atom_coordinates = {}\n",
    "\n",
    "    with open(mol2_file, 'r') as mol2:\n",
    "        reading_bonds = False\n",
    "        reading_atoms = False\n",
    "        for line in mol2:\n",
    "            if line.strip() == '@<TRIPOS>BOND':\n",
    "                reading_bonds = True\n",
    "                continue\n",
    "            elif line.strip() == '@<TRIPOS>ATOM':\n",
    "                reading_atoms = True\n",
    "                continue\n",
    "            elif line.strip().startswith('@<TRIPOS>SUBSTRUCTURE'):\n",
    "                break\n",
    "            elif reading_bonds and line.strip().startswith('@<TRIPOS>'):\n",
    "                reading_bonds = False\n",
    "            elif reading_atoms and line.strip().startswith('@<TRIPOS>'):\n",
    "                reading_atoms = False\n",
    "\n",
    "\n",
    "            if reading_bonds:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    atom1_index = int(parts[1])\n",
    "                    atom2_index = int(parts[2])\n",
    "                    bond_type = parts[3]\n",
    "                    bonds.append((atom1_index, atom2_index))\n",
    "                    bond_types.append(bond_type)\n",
    "\n",
    "            if reading_atoms:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 6:\n",
    "                    atom_index = int(parts[0])\n",
    "                    atom_type = parts[5]\n",
    "                    x, y, z = float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                    atom_types[atom_index] = atom_type.split('.')[0]\n",
    "                    atom_coordinates[atom_index] = (x, y, z)\n",
    "\n",
    "    return bonds, bond_types, atom_types, atom_coordinates\n",
    "\n",
    "def molecule2graph_AA(filename,map_distance):\n",
    "    node_feature = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    mol2_file = CFG.pdbfiles+filename+'/'+filename+'_ligand.mol2'\n",
    "    bonds, bond_types, atom_types, atom_coordinates = read_mol2_bonds_and_atoms(mol2_file)\n",
    "    for atom in atom_types:\n",
    "        node_feature.append(torch.zeros(20))\n",
    "        #node_feature.append(torch.Tensor(atom2emb[atom_types[atom]]))\n",
    "    for i in range(len(bonds)):\n",
    "        bond = bonds[i]\n",
    "        edge_index.append([bond[0] - 1,bond[1] - 1])\n",
    "        coord1 = np.array(atom_coordinates[bond[0]])\n",
    "        coord2 = np.array(atom_coordinates[bond[1]])\n",
    "        dist = [np.sqrt(np.sum((coord1 - coord2)*(coord1 - coord2)))/map_distance]\n",
    "        bond_type = bond_type_dict[bond_types[i]]\n",
    "        edge_attr.append(np.hstack((dist,bond_type)))\n",
    "    \n",
    "    edge_index = np.array(edge_index)\n",
    "    edge_index = edge_index.transpose()\n",
    "    edge_index = torch.Tensor(edge_index)\n",
    "    edge_index = edge_index.to(torch.int64)\n",
    "    edge_attr = torch.Tensor(edge_attr)\n",
    "    node_feature = torch.stack(node_feature)\n",
    "    graph = Data(x = node_feature, edge_index = edge_index,edge_attr = edge_attr)\n",
    "    \n",
    "    return graph, atom_coordinates\n",
    "\n",
    "def id2fullgraph(filename, map_distance):\n",
    "    prot_graph, prot_coord = uniID2graph(filename,map_distance)\n",
    "    mol_graph, mol_coord = molecule2graph(filename,map_distance)\n",
    "    mol_coord = [mol_coord[i] for i in mol_coord]\n",
    "    node_features = torch.cat((prot_graph.x,mol_graph.x),dim = 0)\n",
    "    update_edge_index = mol_graph.edge_index + prot.x.size()[0]\n",
    "    edge_index = torch.cat((prot_graph.edge_index,update_edge_index), dim = 1)\n",
    "    edge_attr = torch.cat((prot_graph.edge_attr,mol_graph.edge_attr), dim = 0)\n",
    "    \n",
    "    new_edge_index = []\n",
    "    new_edge_attr = []\n",
    "    for i in range(len(mol_coord)):\n",
    "        for j in range(len(prot_coord)):\n",
    "            dist_vec = mol_coord[i] - prot_coord[j]\n",
    "            dist = np.sqrt(np.sum(dist_vec*dist_vec))/map_distance\n",
    "            if dist < 1.0:\n",
    "                new_edge_index.append([j,i + len(prot_coord)])\n",
    "                new_edge_attr.append((np.hstack(([dist],bond_type_dict['nc']))))\n",
    "                \n",
    "    new_edge_index = np.array(new_edge_index)\n",
    "    new_edge_index = new_edge_index.transpose()\n",
    "    new_edge_index = torch.Tensor(new_edge_index)\n",
    "    new_edge_index = new_edge_index.to(torch.int64)\n",
    "    new_edge_attr = torch.Tensor(new_edge_attr)\n",
    "    \n",
    "    edge_index = torch.cat((edge_index,new_edge_index), dim = 1)\n",
    "    edge_attr = torch.cat((edge_attr,new_edge_attr), dim = 0)\n",
    "    \n",
    "    graph = Data(x = node_features, edge_index = edge_index,edge_attr = edge_attr)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def molecule2graph_AA(filename,map_distance):\n",
    "    node_feature = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    mol2_file = filename\n",
    "    bonds, bond_types, atom_types, atom_coordinates = read_mol2_bonds_and_atoms(mol2_file)\n",
    "    for atom in atom_types:\n",
    "        #node_feature.append(torch.zeros(20))\n",
    "        node_feature.append(torch.Tensor(atom2emb[atom_types[atom]]))\n",
    "    for i in range(len(bonds)):\n",
    "        bond = bonds[i]\n",
    "        edge_index.append([bond[0] - 1,bond[1] - 1])\n",
    "        coord1 = np.array(atom_coordinates[bond[0]])\n",
    "        coord2 = np.array(atom_coordinates[bond[1]])\n",
    "        dist = [np.sqrt(np.sum((coord1 - coord2)*(coord1 - coord2)))/map_distance]\n",
    "        bond_type = bond_type_dict[bond_types[i]]\n",
    "        edge_attr.append(np.hstack((dist,bond_type)))\n",
    "    \n",
    "    #Master_node\n",
    "    node_feature.append(torch.zeros(len(atom2emb['N'])))\n",
    "    \n",
    "    for i in range(len(node_feature) - 1):\n",
    "        edge_index.append([i,int(len(node_feature)-1)])\n",
    "        bond_type = bond_type_dict['1']\n",
    "        edge_attr.append(np.hstack((1.0,bond_type)))\n",
    "    \n",
    "    edge_index = np.array(edge_index)\n",
    "    edge_index = edge_index.transpose()\n",
    "    edge_index = torch.Tensor(edge_index)\n",
    "    edge_index = edge_index.to(torch.int64)\n",
    "    edge_attr = torch.Tensor(edge_attr)\n",
    "    node_feature = torch.stack(node_feature)\n",
    "    graph = Data(x = node_feature, edge_index = edge_index,edge_attr = edge_attr)\n",
    "    \n",
    "    return graph, atom_coordinates\n",
    "\n",
    "upper2lower = {\n",
    "    \"ala\": \"ALA\",\n",
    "    \"arg\": \"ARG\",\n",
    "    \"asn\": \"ASN\",\n",
    "    \"asp\": \"ASP\",\n",
    "    \"cys\": \"CYS\",\n",
    "    \"gln\": \"GLN\",\n",
    "    \"glu\": \"GLU\",\n",
    "    \"gly\": \"GLY\",\n",
    "    \"his\": \"HIS\",\n",
    "    \"ile\": \"ILE\",\n",
    "    \"leu\": \"LEU\",\n",
    "    \"lys\": \"LYS\",\n",
    "    \"met\": \"MET\",\n",
    "    \"phe\": \"PHE\",\n",
    "    \"pro\": \"PRO\",\n",
    "    \"ser\": \"SER\",\n",
    "    \"thr\": \"THR\",\n",
    "    \"trp\": \"TRP\",\n",
    "    \"tyr\": \"TYR\",\n",
    "    \"val\": \"VAL\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
